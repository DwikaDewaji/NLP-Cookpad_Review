{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPCR-fghCKr7",
        "outputId": "64830c97-b863-4e5b-8594-f941cf0dfdf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-play-scraper in /usr/local/lib/python3.10/dist-packages (1.2.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-play-scraper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Pandas untuk manipulasi dan analisis data\n",
        "pd.options.mode.chained_assignment = None  # Menonaktifkan peringatan chaining\n",
        "import numpy as np  # NumPy untuk komputasi numerik\n",
        "seed = 0\n",
        "np.random.seed(seed)  # Mengatur seed untuk reproduktibilitas\n",
        "import matplotlib.pyplot as plt  # Matplotlib untuk visualisasi data\n",
        "import seaborn as sns  # Seaborn untuk visualisasi data statistik, mengatur gaya visualisasi\n",
        "\n",
        "import datetime as dt  # Manipulasi data waktu dan tanggal\n",
        "import re  # Modul untuk bekerja dengan ekspresi reguler\n",
        "import string  # Berisi konstanta string, seperti tanda baca\n",
        "from nltk.tokenize import word_tokenize  # Tokenisasi teks\n",
        "from nltk.corpus import stopwords  # Daftar kata-kata berhenti dalam teks\n",
        "\n",
        "!pip install sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory  # Stemming (penghilangan imbuhan kata) dalam bahasa Indonesia\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  # Menghapus kata-kata berhenti dalam bahasa Indonesia\n",
        "\n",
        "from wordcloud import WordCloud  # Membuat visualisasi berbentuk awan kata (word cloud) dari teks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TXOZqRvCLvI",
        "outputId": "092ad396-5a98-4e85-9971-673e7ee0433b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk  # Import pustaka NLTK (Natural Language Toolkit).\n",
        "nltk.download('punkt')  # Mengunduh dataset yang diperlukan untuk tokenisasi teks.\n",
        "nltk.download('stopwords')  # Mengunduh dataset yang berisi daftar kata-kata berhenti (stop words) dalam berbagai bahasa."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA41F6A7CNbb",
        "outputId": "a7bbd579-15fa-4e31-cd92-0eea723ccfca"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimpor pustaka google_play_scraper untuk mengakses ulasan dan informasi aplikasi dari Google Play Store.\n",
        "from google_play_scraper import app, reviews_all, Sort\n",
        "\n",
        "# Mengambil semua ulasan dari aplikasi dengan ID 'com.byu.id' di Google Play Store.\n",
        "# Proses scraping mungkin memerlukan beberapa saat tergantung pada jumlah ulasan yang ada.\n",
        "scrapreview = reviews_all(\n",
        "    'com.mufumbo.android.recipe.search',          # ID aplikasi\n",
        "    lang='id',             # Bahasa ulasan (default: 'en')\n",
        "    country='id',          # Negara (default: 'us')\n",
        "    sort=Sort.MOST_RELEVANT, # Urutan ulasan (default: Sort.MOST_RELEVANT)\n",
        "    count=1200             # Jumlah maksimum ulasan yang ingin diambil\n",
        ")"
      ],
      "metadata": {
        "id": "Xjo8lWk2CQXg"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan ulasan dalam file CSV\n",
        "import csv\n",
        "\n",
        "with open('ulasan_aplikasi_cookpad.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Review'])  # Menulis header kolom\n",
        "    for review in scrapreview:\n",
        "        writer.writerow([review['content']])  # Menulis konten ulasan ke dalam file CSV"
      ],
      "metadata": {
        "id": "qgCgN1bzHOvF"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "app_reviews_df = pd.DataFrame(scrapreview)\n",
        "app_reviews_df.shape\n",
        "app_reviews_df.head()\n",
        "app_reviews_df.to_csv('ulasan_aplikasi_cookpad2.csv', index=False)"
      ],
      "metadata": {
        "id": "yaKZJOwYKFXv"
      },
      "execution_count": 97,
      "outputs": []
    }
  ]
}